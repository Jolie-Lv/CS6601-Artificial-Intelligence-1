
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebook.ipynb

import time
from isolation import Board

# Credits if any
# 1)
# 2)
# 3)

class OpenMoveEvalFn:
    def score(self, game, my_player=None):
        """Score the current game state
        Evaluation function that outputs a score equal to how many
        moves are open for AI player on the board minus how many moves
        are open for Opponent's player on the board.

        Note:
            If you think of better evaluation function, do it in CustomEvalFn below.

            Args
                game (Board): The board and game state.
                my_player (Player object): This specifies which player you are.

            Returns:
                float: The current state's score. MyMoves-OppMoves.

            """

        # TODO: finish this function!
        # raise NotImplementedError
        my_moves = game.get_player_moves(my_player=my_player)
        op_moves = game.get_opponent_moves(my_player=my_player)

        return len(my_moves)-len(op_moves)

######################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############
######################################################################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######
################ END OF LOCAL TEST CODE SECTION ######################

class CustomEvalFn:
    def __init__(self, w1=1, w2=1):
        self.w1 = w1/(w1+w2)
        self.w2 = w2/(w1+w2)


    def score(self, game, my_player=None):
        """Score the current game state.

        Custom evaluation function that acts however you think it should. This
        is not required but highly encouraged if you want to build the best
        AI possible.

        Args:
            game (Board): The board and game state.
            my_player (Player object): This specifies which player you are.

        Returns:
            float: The current state's score, based on your own heuristic.
        """
        my_moves = game.get_player_moves(my_player=my_player)
        op_moves = game.get_opponent_moves(my_player=my_player)

        return self.w1*len(my_moves)-self.w2*len(op_moves)
        # TODO: finish this function!
        # raise NotImplementedError

######################################################################
############ DON'T WRITE ANY CODE OUTSIDE THE CLASS! #################
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############
######################################################################

import random
import pdb
class SavedMove:
    '''
        Node of Trie
    '''
    def __init__(self, move = None, move_count = -1, is_terminal = True):
        self.move = move
        self.move_count = move_count
        self.next_move_dict = {}
        self.terminal_moce = is_terminal

class OpeningBook:
    '''
        Class implementing a Trie for openings
    '''
    def __init__(self):
        self.root = SavedMove()

    def add_opening(self, move_history):
        tmp = self.root
        for move_idx, move_pair in enumerate(move_history[0:6]):
            if len(move_pair) < 2:
                tmp.is_terminal = True
                break
            m1, m2 = move_pair[0], move_pair[1]
            # not seen move before
            if m1 not in tmp.next_move_dict:
                tmp.next_move_dict[m1] = SavedMove(move=m1, move_count = move_idx*2, is_terminal = False)
                tmp = tmp.next_move_dict[m1]
                tmp.next_move_dict[m2] = SavedMove(move=m2, move_count = move_idx*2+1, is_terminal=True)
            else:
                tmp = tmp.next_move_dict[m1]
                tmp.is_terminal = False
                if m2 not in tmp.next_move_dict:
                    tmp.next_move_dict[m2] = SavedMove(move=m2, move_count = move_idx*2+1, is_terminal=True)
                tmp = tmp.next_move_dict[m2]

class CustomPlayer:
    # TODO: finish this class!
    """Player that chooses a move using your evaluation function
    and a minimax algorithm with alpha-beta pruning.
    You must finish and test this player to make sure it properly
    uses minimax and alpha-beta to return a good move."""

    def __init__(self, search_depth=5, eval_fn=CustomEvalFn(), w1 = 1, w2 = 1):
        """Initializes your player.

        if you find yourself with a superior eval function, update the default
        value of `eval_fn` to `CustomEvalFn()`

        Args:
            search_depth (int): The depth to which your agent will search
            eval_fn (function): Evaluation function used by your agent
        """
        self.eval_fn = eval_fn
        self.eval_fn.w1 = w1
        self.eval_fn.w2 = w2
        self.search_depth = search_depth
#         self.move_cache = {}
#         self.move_mirroring = False
#         self.in_opening = False
#         self.opening_ptr = None
#         self.my_trie = None

#         # Create opening book
#         self.opening_trie_p1, self.opening_trie_p2 = OpeningBook(), OpeningBook()
#         p1_games = []
#         p2_games = []

#         for p1_game in p1_games:
#             self.opening_trie_p1.add_opening(p1_game)
#         for p2_game in p2_games:
#             self.opening_trie_p2.add_opening(p2_game)

        # pdb.set_trace()

    def move(self, game, time_left):
        """Called to determine one move by your agent

        Note:
            1. Do NOT change the name of this 'move' function. We are going to call
            this function directly.
            2. Call alphabeta instead of minimax once implemented.
        Args:
            game (Board): The board and game state.
            time_left (function): Used to determine time left before timeout

        Returns:
            tuple: (int,int,bool): Your best move
        """
        best_move = None
# #         pdb.set_trace()
#         if self.in_opening:
#             # My player starts
#             if game.move_count == 0:
#                 self.opening_ptr = self.opening_trie_p1.root.next_move_dict[(3,3,False)]
#                 return (3,3,False)
#             # Opp starts
#             elif game.move_count == 1:
#                 self.opening_ptr = self.opening_trie_p2.root
#             # Game has not started from beginning
#             elif not self.move_mirroring and game.move_count > 1:
#                 self.in_opening = False


#             op_move = game.get_opponent_position(my_player=game.get_active_player())
#             op_move = (op_move[0], op_move[1], game.SWAP_FLAG)
#             if self.in_opening and op_move not in self.opening_ptr.next_move_dict.keys():
#                 if game.move_count == 2:
#                     self.move_mirroring = True # start mirroring moves
#                 self.in_opening = False
#             elif self.in_opening:
#                 print(game.move_count)
#                 for move in self.opening_ptr.next_move_dict[op_move].next_move_dict.keys():
#                     my_move = move
#                     break

#                 self.opening_ptr = self.opening_ptr.next_move_dict[op_move].next_move_dict[my_move]
#                 return my_move


#         if game.move_count == 0:
#             self.move_mirroring = True
#             return (3,3,False)

#         if game.move_count == 1:
#             if game.is_spot_open(3,3):
#                 best_move = (3, 3, False)
#                 self.in_opening = False
#                 self.move_mirroring = False
#                 return best_move

#         if self.move_mirroring:
#             op_move = game.get_opponent_position(game.get_active_player())
#             op_move = (op_move[0], op_move[1], game.SWAP_FLAG)
#             mirror_move = (3+(3-op_move[0]),3+(3-op_move[1]),False)
#             if mirror_move in game.get_player_moves(game.get_active_player()):
#                 best_move = mirror_move
#                 return best_move
#             else:
#                 self.move_mirroring = False

#         if best_move is None:
#             if game.move_count < 12:
#                 best_move, utility = alphabeta(self, game, time_left, depth=self.search_depth)
#                 return best_move
#             else:
#                 # self.eval_fn.w2 = 2
#                 for idepth in range(self.search_depth, self.search_depth+10):
#                     best_move, utility = alphabeta(self, game, time_left, depth=idepth)
#                     if time_left() < 5:
#                         return best_move
#                 return best_move
#             # best_move, utility = alphabeta(self, game, time_left, depth=self.search_depth)

        best_move, utility = alphabeta(self, game, time_left, depth=self.search_depth)
        return best_move

    def utility(self, game, my_turn):
        """You can handle special cases here (e.g. endgame)"""
        u = None
        u = self.eval_fn.score(game, game.get_active_player())
        if not my_turn:
            u = u * -1
        return u

###################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE CLASS! ################
###### IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ###########
###################################################################

def max_value(player, game, time_left, max_depth, curr_depth, alpha, beta, my_turn):
    if curr_depth == max_depth:
        v = player.eval_fn.score(game, game.get_active_player())
        return None, v

    else:
        v = float("-inf")
        moves = game.get_player_moves(game.get_active_player())
        for move in moves:
            new_board, is_over, is_winner = game.forecast_move(move)
            if is_over:
                return move, +50

            if time_left() < 10:
                return move, player.eval_fn.score(new_board, new_board.get_active_player())

            else:
                _, val = min_value(player, new_board, time_left, max_depth, curr_depth+1, alpha, beta, not my_turn)

            if val >= beta:
                return None, v

            if val > v:
                best_move = move
                v = val

            alpha = max(alpha, v)

    return best_move, v

def min_value(player, game, time_left, max_depth, curr_depth, alpha, beta, my_turn):
    if curr_depth == max_depth:
        return None, -1*player.eval_fn.score(game, game.get_active_player())

    else:
        v = float("inf")
        moves = game.get_player_moves(game.get_active_player())
        for move in moves:
            new_board, is_over, is_winner = game.forecast_move(move)

            if is_over:
                return move, -50

            if time_left() < 10:
                return move, -1*player.eval_fn.score(new_board, new_board.get_active_player())

            else:
                _, val = max_value(player, new_board, time_left, max_depth, curr_depth+1, alpha, beta, not my_turn)

            if v <= alpha:
                return None, v

            if val < v:
                best_move = move
                v = val

            beta = max(beta, v)

    return best_move, v

def alphabeta(player, game, time_left, depth, alpha=float("-inf"), beta=float("inf"), my_turn=True):
    """Implementation of the alphabeta algorithm.

    Args:
        player (CustomPlayer): This is the instantiation of CustomPlayer()
            that represents your agent. It is used to call anything you need
            from the CustomPlayer class (the utility() method, for example,
            or any class variables that belong to CustomPlayer())
        game (Board): A board and game state.
        time_left (function): Used to determine time left before timeout
        depth: Used to track how deep you are in the search tree
        alpha (float): Alpha value for pruning
        beta (float): Beta value for pruning
        my_turn (bool): True if you are computing scores during your turn.

    Returns:
        (tuple, int): best_move, val
    """
    # if my_turn: return max_value(player, game, time_left, depth, 0, alpha, beta, my_turn)
    # else: return min_value(player, game, time_left, depth, 0, alpha, beta, my_turn)
    return max_value(player, game, time_left, depth, 0, alpha, beta, my_turn)

######################################################################
########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################
######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############
######################################################################
##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######
# tests.alphabetaTest1(CustomPlayer, alphabeta) #you can uncomment this line to run your test
# %time tests.alphabetaTest2(CustomPlayer, alphabeta) #you can uncomment this line to run your test
# tests.beatRandom(CustomPlayer)
# tests.beatMiniMax(CustomPlayerAlphaBeta, CustomPlayer)
################ END OF LOCAL TEST CODE SECTION ######################